name: CI

on:
  push:
    branches:
    - master
    - v*
  pull_request:
    branches:
    - master
    - v*

jobs:
  build:
    strategy:
      matrix:
        version:
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "2.7.3"
          scala:  "2.11"
          python: "3.6"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "2.7.3"
          scala:  "2.11"
          python: "3.7"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "2.7.3"
          scala:  "2.12"
          python: "3.6"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "2.7.3"
          scala:  "2.12"
          python: "3.7"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "3.1.0"
          scala:  "2.11"
          python: "3.6"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "3.1.0"
          scala:  "2.11"
          python: "3.7"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "3.1.0"
          scala:  "2.12"
          python: "3.6"
        - spark:  "2.4.8"
          java:   "8"
          hadoop: "3.1.0"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.0.3"
          java:   "8"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.0.3"
          java:   "8"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.0.3"
          java:   "8"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.0.3"
          java:   "8"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.0.3"
          java:   "8"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.0.3"
          java:   "8"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.0.3"
          java:   "11"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.0.3"
          java:   "11"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.0.3"
          java:   "11"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.0.3"
          java:   "11"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.0.3"
          java:   "11"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.0.3"
          java:   "11"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.1.2"
          java:   "8"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.1.2"
          java:   "8"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.1.2"
          java:   "8"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.1.2"
          java:   "8"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.1.2"
          java:   "8"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.1.2"
          java:   "8"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.1.2"
          java:   "11"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.1.2"
          java:   "11"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.1.2"
          java:   "11"
          hadoop: "2.7.4"
          scala:  "2.12"
          python: "3.8"
        - spark:  "3.1.2"
          java:   "11"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.6"
        - spark:  "3.1.2"
          java:   "11"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.7"
        - spark:  "3.1.2"
          java:   "11"
          hadoop: "3.2.0"
          scala:  "2.12"
          python: "3.8"
    runs-on: ubuntu-20.04
    env:
      IMAGE_NAME: spark-k8s-addons
      SELF_VERSION: "v5"
      BASE_VERSION: "v3"
      SPARK_VERSION: "${{ matrix.version.spark }}"
      JAVA_VERSION: "${{ matrix.version.java }}"
      HADOOP_VERSION: "${{ matrix.version.hadoop }}"
      SCALA_VERSION: "${{ matrix.version.scala }}"
      PYTHON_VERSION: "${{ matrix.version.python }}"
    steps:
    - name: Set up Java
      uses: actions/setup-java@v2
      with:
        distribution: adopt
        java-version: '${{ matrix.version.java }}'
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Install tera-cli
      run: |-
        wget https://github.com/guangie88/tera-cli/releases/download/v0.4.0/tera_linux_amd64 -O /tmp/tera
        chmod +x /tmp/tera
    - name: Check differences between ci.yml and ci.yml.tmpl
      run: |-
        cp .github/workflows/ci.yml .github/workflows/ci.yml.backup
        TERA=/tmp/tera ./templates/apply-vars.sh
        if ! diff .github/workflows/ci.yml .github/workflows/ci.yml.backup; then echo "ci.yml.tmpl and ci.yml differs!" && exit 1; fi
    - name: Build Docker image
      run: |-
        PY4J_SRC="$(docker run --rm -t --entrypoint sh "dsaidgovsg/spark-k8s-py:${BASE_VERSION}_${SPARK_VERSION}_hadoop-${HADOOP_VERSION}_scala-${SCALA_VERSION}" -c 'ls --color=never ${SPARK_HOME}/python/lib/py4j-*.zip' | tr -d "\r\n")"
        echo "PY4J_SRC - ${PY4J_SRC}"
        TAG_NAME="${SELF_VERSION}_${SPARK_VERSION}_hadoop-${HADOOP_VERSION}_scala-${SCALA_VERSION}_java-${JAVA_VERSION}_python-${PYTHON_VERSION}"
        docker build . -t "${IMAGE_NAME}:${TAG_NAME}" \
          --build-arg BASE_VERSION="${BASE_VERSION}" \
          --build-arg SPARK_VERSION="${SPARK_VERSION}" \
          --build-arg JAVA_VERSION="${JAVA_VERSION}" \
          --build-arg HADOOP_VERSION="${HADOOP_VERSION}" \
          --build-arg SCALA_VERSION="${SCALA_VERSION}" \
          --build-arg PYTHON_VERSION="${PYTHON_VERSION}" \
          --build-arg PY4J_SRC="${PY4J_SRC}"
    - name: Push Docker image
      run: bash push-images.sh
      env:
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        IMAGE_ORG: ${{ secrets.IMAGE_ORG }}
      if: github.event_name == 'push'
